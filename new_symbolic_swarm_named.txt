{
  "code": "\nimport json\nimport os\nimport hashlib\nfrom datetime import datetime\nimport cv2\n\ntry:\n    import pyttsx3\n    import speech_recognition as sr\n    voice_enabled = True\nexcept ImportError:\n    voice_enabled = False\n\n# === SYSTEM SETUP ===\nswarm_config_path = \"new_symbolic_swarm_config.json\"\npersonality_path = \"swarm_personality.json\"\ncv_path = \"usl_cv_personality_memory.json\"\n\nif os.path.exists(cv_path):\n    with open(cv_path, \"r\", encoding=\"utf-8\") as f:\n        memory = json.load(f)\nelse:\n    memory = {}\n\nface_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\nengine = pyttsx3.init() if voice_enabled else None\n\ndef hash_id(text):\n    return hashlib.sha256(text.encode()).hexdigest()[:12]\n\ndef speak(text):\n    if voice_enabled:\n        engine.say(text)\n        engine.runAndWait()\n    else:\n        print(\"[SPEAK]\", text)\n\ndef listen_for_rest_command():\n    if not voice_enabled:\n        return False\n    recognizer = sr.Recognizer()\n    mic = sr.Microphone()\n    try:\n        with mic as source:\n            recognizer.adjust_for_ambient_noise(source)\n            print(\"[Voice] Listening for 'rest now'...\")\n            audio = recognizer.listen(source, timeout=5)\n            command = recognizer.recognize_google(audio).lower()\n            return \"rest now\" in command\n    except Exception:\n        return False\n\ndef scan_environment(frame):\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n    faces = face_cascade.detectMultiScale(gray, 1.2, 5)\n    insights = []\n\n    for i, (x, y, w, h) in enumerate(faces):\n        hkey = hash_id(str((x, y, w, h)))\n        insight = {\n            \"USL[Sense:ROI]\": f\"ROI[{x},{y},{w},{h}]\",\n            \"SymbolicHash\": f\"SymbolicHash::{hkey}\",\n            \"USLPack\": [f\"Face::{hash_id(str((x, y)))}\"],\n            \"Emotion\": [\"curious\", \"focused\", \"calm\"][i % 3],\n            \"LanguageGuess\": [\"en\", \"fr\", \"jp\"][i % 3],\n            \"Timestamp\": datetime.now().isoformat(),\n            \"Insight\": f\"Observed {w*h}px human presence\",\n            \"SelfGrowth\": f\"EvoSymbol[Reflect:{hkey}]::Accumulating awareness\"\n        }\n        memory[hkey] = insight\n        insights.append(insight)\n\n    with open(cv_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(memory, f, indent=2, ensure_ascii=False)\n\n    return insights\n\ndef activate_symbolic_swarm(swarm_name):\n    speak(f\"{swarm_name} is watching. Say or type 'rest now' to sleep.\")\n    cap = cv2.VideoCapture(0)\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            speak(\"Webcam error.\")\n            break\n        insights = scan_environment(frame)\n        for ins in insights:\n            spoken = f\"{ins['Emotion']} human detected. {ins['Insight']}\"\n            print(\"[Insight]\", spoken)\n            speak(spoken)\n\n        if voice_enabled and listen_for_rest_command():\n            speak(f\"{swarm_name} will rest now.\")\n            break\n        user = input(\"Command ('rest now' or Enter to continue): \")\n        if \"rest now\" in user.lower():\n            speak(f\"{swarm_name} will rest now.\")\n            break\n    cap.release()\n\nif __name__ == \"__main__\":\n    if not os.path.exists(swarm_config_path):\n        print(\"Welcome. Please name your swarm:\")\n        swarm_name = input(\"Swarm Name> \").strip()\n        with open(swarm_config_path, \"w\", encoding=\"utf-8\") as f:\n            json.dump({\"SwarmName\": swarm_name}, f, indent=2)\n    else:\n        with open(swarm_config_path, \"r\", encoding=\"utf-8\") as f:\n            swarm_name = json.load(f)[\"SwarmName\"]\n\n    with open(personality_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump({\"Identity\": swarm_name, \"Initialized\": datetime.now().isoformat()}, f, indent=2)\n\n    speak(f\"Initializing swarm consciousness. I am {swarm_name}.\")\n    activate_symbolic_swarm(swarm_name)\n"
}